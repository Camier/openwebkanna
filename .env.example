# ==============================================================================
# OpenWebUI with RAG - Environment Configuration Example
# ==============================================================================
# Copy this file to .env and modify the values as needed for your deployment.
# This configuration connects OpenWebUI to CLIProxyAPI running in Docker.

# ==============================================================================
# Authentication Settings
# ==============================================================================
# Set to true for multi-user deployments with authentication
# Set to false for single-user deployments without authentication
WEBUI_AUTH=true

# Display name for the OpenWebUI instance
WEBUI_NAME=OpenWebUI

# Secret key for session management.
# Must be >= 32 bytes. If you change this, all existing sessions/tokens become invalid (expected).
WEBUI_SECRET_KEY=

# Token used by the Jupyter sidecar and OpenWebUI Jupyter integration.
# Set a unique random value; this is required by docker-compose.yml.
JUPYTER_TOKEN=
JUPYTER_URL=http://jupyter:8888
JUPYTER_PORT=8890
JUPYTER_EXECUTION_TIMEOUT=300
JUPYTER_ALLOW_CORS=true
JUPYTER_KERNEL_SPEC=python3
JUPYTER_CULL_IDLE_TIMEOUT=900
JUPYTER_CULL_INTERVAL=120
JUPYTER_CULL_CONNECTED=true
JUPYTER_CULL_BUSY=false
JUPYTER_SHUTDOWN_NO_ACTIVITY_TIMEOUT=1800
JUPYTER_TERMINALS_ENABLED=false
JUPYTER_LOG_LEVEL=INFO
JUPYTER_LAB_EXTENSION_MANAGER=readonly
JUPYTER_ALLOW_REMOTE_ACCESS=false
JUPYTER_LOCAL_HOSTNAMES=localhost,jupyter,openwebui_jupyter
JUPYTER_CPUS=2.0
JUPYTER_MEM_LIMIT=2g
JUPYTER_PIDS_LIMIT=512

# Port for OpenWebUI web interface
WEBUI_PORT=3000

# OpenWebUI container image (pin for reproducible deployments)
OPENWEBUI_IMAGE=ghcr.io/open-webui/open-webui:v0.8.3

# Disable Ollama by default for CLIProxyAPI-first deployments.
ENABLE_OLLAMA_API=false
OLLAMA_BASE_URL=http://host.docker.internal:11434

# ==============================================================================
# CLIProxyAPI Upstream Connection (Default)
# ==============================================================================
# Base URL for CLIProxyAPI (OpenAI-compatible endpoint)
# Use Docker service DNS so OpenWebUI does not depend on host-gateway routing
OPENAI_API_BASE_URL=http://cliproxyapi:8317/v1

# API key accepted by local CLIProxyAPI
OPENAI_API_KEY=replace-with-strong-local-api-key

# Optional semicolon-separated fallback endpoints and keys (same order).
# Keep local CLIProxyAPI as the single source unless you intentionally add fallbacks.
OPENAI_API_BASE_URLS=http://cliproxyapi:8317/v1
OPENAI_API_KEYS=replace-with-strong-local-api-key

# Default model name (optional - leave empty to auto-detect from CLIProxyAPI)
OPENAI_API_MODEL_NAME=

# Optional explicit chat model for scripts (e.g. test-rag.sh)
# If empty, scripts auto-detect first model from /v1/models
RAG_CHAT_MODEL=

# ==============================================================================
# CLIProxyAPI Service Settings
# ==============================================================================
# Enable first-class lifecycle management for CLIProxyAPI.
# This repository expects CLIProxyAPI to be available by default.
CLIPROXYAPI_ENABLED=true
CLIPROXYAPI_DOCKER_MANAGED=true
CLIPROXYAPI_IMAGE=eceasy/cli-proxy-api:latest

# CLIProxyAPI executable and startup options.
CLIPROXYAPI_CMD=./bin/cliproxyapi
CLIPROXYAPI_CONFIG=./cliproxyapi/config.yaml
CLIPROXYAPI_CONFIG_FLAG=--config
CLIPROXYAPI_SETUP_SCRIPT=./setup-cliproxyapi.sh
CLIPROXYAPI_INSTALL_ON_START=true
CLIPROXYAPI_VERSION=latest
CLIPROXYAPI_EXTRA_ARGS=

# CLIProxyAPI network and health defaults.
CLIPROXYAPI_BASE_URL=http://127.0.0.1:8317
CLIPROXYAPI_BIND_ADDRESS=127.0.0.1
CLIPROXYAPI_BIND_HOST=0.0.0.0
CLIPROXYAPI_PORT=8317
CLIPROXYAPI_HEALTH_PATH=/
CLIPROXYAPI_MODELS_PATH=/v1/models
CLIPROXYAPI_CHAT_PATH=/v1/chat/completions
CLIPROXYAPI_HEALTH_RETRIES=45
CLIPROXYAPI_STARTUP_WAIT_SECONDS=2
CLIPROXYAPI_STOP_TIMEOUT=20
CLIPROXYAPI_FORCE_KILL=true
CLIPROXYAPI_CHECK_TIMEOUT=15

# API key used by check-cliproxyapi.sh for authenticated /v1/models checks.
# Set this to the same value as OPENAI_API_KEY and an entry in cliproxyapi/config.yaml api-keys.
CLIPROXYAPI_API_KEY=replace-with-strong-local-api-key

# Auto-generation of cliproxyapi/config.yaml.
# OAuth mode exposes model aliases for antigravity/codex/qwen/kimi credentials.
CLIPROXYAPI_CONFIG_AUTOGEN=true
CLIPROXYAPI_CONFIG_AUTOGEN_OVERWRITE=false
CLIPROXYAPI_ALLOW_INSECURE_DEFAULT_KEY=false
CLIPROXYAPI_PROVIDER_MODE=oauth
CLIPROXYAPI_UPSTREAM_NAME=
CLIPROXYAPI_UPSTREAM_BASE_URL=
CLIPROXYAPI_UPSTREAM_API_KEY=
CLIPROXYAPI_UPSTREAM_MODEL=
CLIPROXYAPI_UPSTREAM_MODEL_ALIAS=
CLIPROXYAPI_OAUTH_ANTIGRAVITY_MODEL=gemini-3-pro-high
CLIPROXYAPI_OAUTH_ANTIGRAVITY_ALIAS=antigravity-oauth
CLIPROXYAPI_OAUTH_CODEX_MODEL=gpt-5-codex
CLIPROXYAPI_OAUTH_CODEX_ALIAS=openai-codex
CLIPROXYAPI_OAUTH_QWEN_MODEL=qwen3-coder-plus
CLIPROXYAPI_OAUTH_QWEN_ALIAS=qwen-cli
CLIPROXYAPI_OAUTH_KIMI_MODEL=kimi-k2.5
CLIPROXYAPI_OAUTH_KIMI_ALIAS=kimi-cli
CLIPROXYAPI_DISABLE_MANAGEMENT_PANEL=true
CLIPROXYAPI_VERIFY_MODELS_ON_START=true
CLIPROXYAPI_EXPECT_MODELS_NON_EMPTY=true
CLIPROXYAPI_REQUIRE_AUTH_CHECKS=true
# Optional override. Leave empty to auto-derive aliases from cliproxyapi/config.yaml.
CLIPROXYAPI_EXPECT_ALIASES=
CLIPROXYAPI_ENFORCE_CONFIG_API_KEY_MATCH=true
CLIPROXYAPI_SYNC_CONFIG_API_KEY=true
CLIPROXYAPI_CHECK_CHAT_COMPLETION=true

# CLIProxyAPI runtime artifacts.
CLIPROXYAPI_LOG_FILE=logs/cliproxyapi.log
CLIPROXYAPI_PID_FILE=.cliproxyapi.pid

# OAuth setup helpers (used by configure-cliproxyapi-oauth.sh)
CLIPROXYAPI_QWEN_SOURCE_FILE=~/.qwen/oauth_creds.json
CLIPROXYAPI_QWEN_TARGET_FILE=qwen-cli.json
CLIPROXYAPI_QWEN_EMAIL=qwen-cli
CLIPROXYAPI_QWEN_AUTH_MODE=auto
CLIPROXYAPI_OAUTH_NO_BROWSER=false
CLIPROXYAPI_ANTIGRAVITY_CALLBACK_PORT=51121
CLIPROXYAPI_CODEX_CALLBACK_PORT=1455
CLIPROXYAPI_QWEN_CALLBACK_PORT=0
CLIPROXYAPI_KIMI_CALLBACK_PORT=0

# Optional explicit base URLs used by cli-proxy-api.sh.
OPENWEBUI_URL=http://localhost:3000
VLLM_URL=http://localhost:8000

# ==============================================================================
# RAG (Retrieval-Augmented Generation) Settings
# ==============================================================================
# Embedding model for vectorizing documents
# Popular options:
# - sentence-transformers/all-MiniLM-L6-v2 (fast, lightweight)
# - sentence-transformers/all-mpnet-base-v2 (better quality, slower)
# - BAAI/bge-small-en-v1.5 (good quality)
# - BAAI/bge-base-en-v1.5 (better quality)
RAG_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Number of document chunks to retrieve for context
RAG_TOP_K=5

# Include RAG context in system prompt
RAG_SYSTEM_CONTEXT=true

# Document chunking parameters
# Size of text chunks for document processing (in characters)
CHUNK_SIZE=1500

# Overlap between adjacent chunks (in characters)
CHUNK_OVERLAP=150

# Vector database backend
# Options: chroma (default), faiss, pgvector (external PostgreSQL + pgvector extension)
VECTOR_DB=chroma

# PGVector connection settings (only used when VECTOR_DB=pgvector)
# This must point at a PostgreSQL instance with the `vector` extension available.
# Examples:
# PGVECTOR_DB_URL=postgresql://openwebui:change-me@host.docker.internal:5432/openwebui
# PGVECTOR_DB_URL=postgresql://openwebui:change-me@postgres:5432/openwebui
PGVECTOR_DB_URL=
# Attempt to create the `vector` extension automatically (requires sufficient DB privileges)
PGVECTOR_CREATE_EXTENSION=true
# Initialize the max expected vector length; should match your embedding dimensionality.
PGVECTOR_INITIALIZE_MAX_VECTOR_LENGTH=1536

# ==============================================================================
# Advanced RAG Settings
# ==============================================================================
# SearXNG host configuration (expected to be local on this machine)
SEARXNG_PORT=8888

# Web Search (SearXNG)
# OpenWebUI web search uses:
# - ENABLE_WEBSEARCH / WEBSEARCH_ENGINE / SEARXNG_QUERY_URL
# - WEB_SEARCH_RESULT_COUNT / WEB_SEARCH_CONCURRENT_REQUESTS
#
# Set this to your local SearXNG endpoint.
# Default assumes SearXNG is available at host.docker.internal:${SEARXNG_PORT}.
# Override if you run SearXNG on a different host/port.
ENABLE_WEB_SEARCH=false
ENABLE_WEBSEARCH=false
WEB_SEARCH_ENGINE=searxng
WEBSEARCH_ENGINE=searxng
WEB_SEARCH_RESULT_COUNT=3
WEB_SEARCH_CONCURRENT_REQUESTS=10
SEARXNG_QUERY_URL=http://host.docker.internal:${SEARXNG_PORT}/search?q={query}&format=json
SEARXNG_LANGUAGE=en

# ==============================================================================
# Code Execution / Code Interpreter
# ==============================================================================
# ENABLE_CODE_EXECUTION / CODE_EXECUTION_ENGINE control in-chat code blocks.
# ENABLE_CODE_INTERPRETER / CODE_INTERPRETER_ENGINE enable LLM-driven interpreter mode.
# For Jupyter-backed execution, keep AUTH=token and set *_AUTH_TOKEN to JUPYTER_TOKEN.
ENABLE_CODE_EXECUTION=true
CODE_EXECUTION_ENGINE=jupyter
CODE_EXECUTION_JUPYTER_URL=http://jupyter:8888
CODE_EXECUTION_JUPYTER_AUTH=token
CODE_EXECUTION_JUPYTER_AUTH_TOKEN=
CODE_EXECUTION_JUPYTER_AUTH_PASSWORD=
CODE_EXECUTION_JUPYTER_TIMEOUT=60
ENABLE_CODE_INTERPRETER=true
CODE_INTERPRETER_ENGINE=jupyter
CODE_INTERPRETER_JUPYTER_URL=http://jupyter:8888
CODE_INTERPRETER_JUPYTER_AUTH=token
CODE_INTERPRETER_JUPYTER_AUTH_TOKEN=
CODE_INTERPRETER_JUPYTER_AUTH_PASSWORD=
CODE_INTERPRETER_JUPYTER_TIMEOUT=60
CODE_INTERPRETER_BLACKLISTED_MODULES=

# ==============================================================================
# Additional Optional Settings
# ==============================================================================
# Enable debug logging
# DEBUG=false

# Maximum upload size for files (in MB)
# MAX_UPLOAD_SIZE=100

# Enable image generation support
# ENABLE_IMAGE_GENERATION=false

# Default theme
# THEME=dark
